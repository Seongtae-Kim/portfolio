{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU를 사용합니다. GeForce GTX 1050 Ti with Max-Q Design\n",
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "from winterschool_trainer import WinterSchool_BERT\n",
    "t = WinterSchool_BERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kcbert                                    beomi@github 님이 만드신 KcBERT 학습데이터\nkorean_chatbot_data                       songys@github 님이 만드신 챗봇 문답 데이터\nkorean_hate_speech                        {inmoonlight,warnikchow,beomi}@github 님이 만드신 혐오댓글데이터\nkorean_parallel_koen_news                 jungyeul@github 님이 만드신 병렬 말뭉치\nkorean_petitions                          lovit@github 님이 만드신 2017.08 ~ 2019.03 청와대 청원데이터\nkornli                                    KakaoBrain 에서 제공하는 Natural Language Inference (NLI) 데이터\nkorsts                                    KakaoBrain 에서 제공하는 Semantic Textual Similarity (STS) 데이터\nkowikitext                                lovit@github 님이 만드신 wikitext 형식의 한국어 위키피디아 데이터\nnamuwikitext                              lovit@github 님이 만드신 wikitext 형식의 나무위키 데이터\nnaver_changwon_ner                        네이버 + 창원대 NER shared task data\nnsmc                                      e9t@github 님이 만드신 Naver sentiment movie corpus v1.0\nquestion_pair                             songys@github 님이 만드신 질문쌍(Paired Question v.2)\nmodu_news                                 국립국어원에서 만든 모두의 말뭉치: 뉴스 말뭉치\nmodu_messenger                            국립국어원에서 만든 모두의 말뭉치: 메신저 말뭉치\nmodu_mp                                   국립국어원에서 만든 모두의 말뭉치: 형태 분석 말뭉치\nmodu_ne                                   국립국어원에서 만든 모두의 말뭉치: 개체명 분석 말뭉치\nmodu_spoken                               국립국어원에서 만든 모두의 말뭉치: 구어 말뭉치\nmodu_web                                  국립국어원에서 만든 모두의 말뭉치: 웹 말뭉치\nmodu_written                              국립국어원에서 만든 모두의 말뭉치: 문어 말뭉치\nopen_subtitles                            Open parallel corpus (OPUS) 에서 제공하는 영화 자막 번역 병렬 말뭉치\naihub_translation                         AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어 + 대화 + 뉴스 + 한국문화 + 조례 + 지자체웹사이트)\naihub_spoken_translation                  AI Hub 에서 제공하는 번역용 병렬 말뭉치 (구어)\naihub_conversation_translation            AI Hub 에서 제공하는 번역용 병렬 말뭉치 (대화)\naihub_news_translation                    AI Hub 에서 제공하는 번역용 병렬 말뭉치 (뉴스)\naihub_korean_culture_translation          AI Hub 에서 제공하는 번역용 병렬 말뭉치 (한국문화)\naihub_decree_translation                  AI Hub 에서 제공하는 번역용 병렬 말뭉치 (조례)\naihub_government_website_translation      AI Hub 에서 제공하는 번역용 병렬 말뭉치 (지자체웹사이트)\n"
     ]
    }
   ],
   "source": [
    "t.get_corpus_specifications()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU를 사용합니다. GeForce GTX 1050 Ti with Max-Q Design\n",
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "Some weights of the model checkpoint at /home/seongtae/SynologyDrive/SIRE/Projects/KR-BERT/KR-BERT/krbert_pytorch/pretrained/pytorch_model_char16424_ranked.bin were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/seongtae/SynologyDrive/SIRE/Projects/KR-BERT/KR-BERT/krbert_pytorch/pretrained/pytorch_model_char16424_ranked.bin and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "BERT 준비 완료\n"
     ]
    }
   ],
   "source": [
    "from winterschool_trainer import Sentiment_Analysis\n",
    "sent_analyzer = Sentiment_Analysis(train_ratio=0.9, batch_size=8, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/seongtae/Korpora/nsmc/ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/seongtae/Korpora/nsmc/ratings_test.txt\n"
     ]
    }
   ],
   "source": [
    "nsmc = sent_analyzer.build_corpus(\"nsmc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:06:23.367560Z",
     "start_time": "2021-01-28T06:06:23.277997Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      텍스트  감정  라벨\n",
       "0                                     아 더빙.. 진짜 짜증나네요 목소리  부정   0\n",
       "1                       흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나  긍정   1\n",
       "2                                       너무재밓었다그래서보는것을추천한다  부정   0\n",
       "3                           교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정  부정   0\n",
       "4       사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...  긍정   1\n",
       "...                                                   ...  ..  ..\n",
       "199995          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함  긍정   1\n",
       "199996       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO  부정   0\n",
       "199997                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다  부정   0\n",
       "199998     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네  부정   0\n",
       "199999                                         마무리는 또 왜이래  부정   0\n",
       "\n",
       "[200000 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>텍스트</th>\n      <th>감정</th>\n      <th>라벨</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n      <td>긍정</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n      <td>긍정</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n      <td>긍정</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>마무리는 또 왜이래</td>\n      <td>부정</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "texts = nsmc.get_all_texts()\n",
    "labels = nsmc.get_all_labels()\n",
    "d= {\"텍스트\":texts,\"감정\":[\"긍정\" if l==1 else \"부정\" for l in labels], \"라벨\":labels}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35d82d205417439d955354d212939cd3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sent_analyzer.encode(texts[:100], labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1503159d168b46d79f27c202562c7ed4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 1/1 | step: 2/12                           mean training loss: 0.06\nepoch: 1/1 | step: 3/12                           mean training loss: 0.11\nepoch: 1/1 | step: 4/12                           mean training loss: 0.18\nepoch: 1/1 | step: 5/12                           mean training loss: 0.24\nepoch: 1/1 | step: 6/12                           mean training loss: 0.30\nepoch: 1/1 | step: 7/12                           mean training loss: 0.36\nepoch: 1/1 | step: 8/12                           mean training loss: 0.41\nepoch: 1/1 | step: 9/12                           mean training loss: 0.47\nepoch: 1/1 | step: 10/12                          mean training loss: 0.53\nepoch: 1/1 | step: 11/12                          mean training loss: 0.59\nepoch: 1/1 | step: 12/12                          mean training loss: 0.65\n"
     ]
    }
   ],
   "source": [
    "sent_analyzer.prepare()\n",
    "sent_analyzer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Validation Loss: 0.68\n  Validation Accuracy: 0.31\n"
     ]
    }
   ],
   "source": [
    "sent_analyzer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2072da694105494081af89a98286db25"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bbbc224db48e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"내가 봤을 때 그렇게 재밌는거 같지는 않다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SynologyDrive/SIRE/Projects/2021_Winter_School/BERT/winterschool_trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             logit, loss = self.bert(self.input_ids, token_type_ids=None,\n\u001b[0m\u001b[1;32m    252\u001b[0m                                     attention_mask=self.attention_masks)\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"긍정\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"부정\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "sent_analyzer.predict(\"내가 봤을 때 그렇게 재밌는거 같지는 않다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Sentence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (Token Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"naver_changwon_ner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-Of-Speech Tagging (Token Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Role Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"korean_parallel_koen_news\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coreference Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"kornli\"\n",
    "\"korsts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hate Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"korean_hate_speech\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"korean_chatbot_data\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}