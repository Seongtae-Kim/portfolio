{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jiant: GLUE 벤치마크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021-03-30 전산언어학특수과제: GLUE BENCHMARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 사전 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **git clone https://github.com/nyu-mll/jiant.git**<br>\n",
    "- **cd jiant**<br>\n",
    "- **pip install -r requirements.txt**<br>\n",
    "<br>\n",
    "- **export PYTHONPATH=/path/to/jiant:$PYTHONPATH**<br>\n",
    "export PYTHONPATH=/home/seongtae/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant:$PYTHONPATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T19:53:14.993356Z",
     "start_time": "2021-04-09T19:53:13.467365Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"./jiant\")\n",
    "\n",
    "from jiant.proj.simple import runscript as run\n",
    "import jiant.scripts.download_data.runscript as downloader\n",
    "\n",
    "EXP_DIR = \"./jiant/jiant/exp\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLUE Task 키워드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T19:53:15.007936Z",
     "start_time": "2021-04-09T19:53:15.005565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cola', 'qnli', 'mnli_mismatched', 'glue_diagnostics', 'stsb', 'mnli', 'sst', 'wnli', 'rte', 'qqp', 'mrpc'}\n"
     ]
    }
   ],
   "source": [
    "print(downloader.GLUE_TASKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T19:53:15.031201Z",
     "start_time": "2021-04-09T19:53:15.019176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'record', 'wic', 'rte', 'superglue_broadcoverage_diagnostics', 'superglue_winogender_diagnostics', 'wsc', 'cb', 'multirc', 'boolq', 'copa'}\n"
     ]
    }
   ],
   "source": [
    "print(downloader.SUPERGLUE_TASKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNLI Test (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T19:53:28.829137Z",
     "start_time": "2021-04-09T19:53:15.040528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/seongtae/.cache/huggingface/datasets/glue/mnli/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and generated configs for 'mnli' (1/1)\n"
     ]
    }
   ],
   "source": [
    "downloader.download_data([\"mnli\"], f\"{EXP_DIR}/tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T19:53:28.847375Z",
     "start_time": "2021-04-09T19:53:28.844442Z"
    }
   },
   "outputs": [],
   "source": [
    "args = run.RunConfiguration(\n",
    "   run_name=\"simple\",\n",
    "   exp_dir=EXP_DIR,\n",
    "   data_dir=f\"{EXP_DIR}/tasks\",\n",
    "   hf_pretrained_model_name_or_path=\"bert-base-uncased\", # transformers.Autoconfig에 등록된 모든 모델들 및 경로 지정 후 따로 사용 가능\n",
    "   tasks=\"mnli\",\n",
    "   train_batch_size=1,\n",
    "   num_train_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T19:53:58.241603Z",
     "start_time": "2021-04-09T19:53:28.863664Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from start\n",
      "  jiant_task_container_config_path: ./jiant/jiant/exp/run_configs/simple_config.json\n",
      "  output_dir: ./jiant/jiant/exp/runs/simple\n",
      "  hf_pretrained_model_name_or_path: bert-base-uncased\n",
      "  model_path: ./jiant/jiant/exp/models/bert/model/model.p\n",
      "  model_config_path: ./jiant/jiant/exp/models/bert/model/config.json\n",
      "  model_load_mode: from_transformers\n",
      "  do_train: True\n",
      "  do_val: True\n",
      "  do_save: False\n",
      "  do_save_last: False\n",
      "  do_save_best: False\n",
      "  write_val_preds: False\n",
      "  write_test_preds: False\n",
      "  eval_every_steps: 0\n",
      "  save_every_steps: 0\n",
      "  save_checkpoint_every_steps: 0\n",
      "  no_improvements_for_n_evals: 0\n",
      "  keep_checkpoint_when_done: False\n",
      "  force_overwrite: False\n",
      "  seed: -1\n",
      "  learning_rate: 1e-05\n",
      "  adam_epsilon: 1e-08\n",
      "  max_grad_norm: 1.0\n",
      "  optimizer_type: adam\n",
      "  no_cuda: False\n",
      "  fp16: False\n",
      "  fp16_opt_level: O1\n",
      "  local_rank: -1\n",
      "  server_ip: \n",
      "  server_port: \n",
      "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "Using seed: 1712373767\n",
      "{\n",
      "  \"jiant_task_container_config_path\": \"./jiant/jiant/exp/run_configs/simple_config.json\",\n",
      "  \"output_dir\": \"./jiant/jiant/exp/runs/simple\",\n",
      "  \"hf_pretrained_model_name_or_path\": \"bert-base-uncased\",\n",
      "  \"model_path\": \"./jiant/jiant/exp/models/bert/model/model.p\",\n",
      "  \"model_config_path\": \"./jiant/jiant/exp/models/bert/model/config.json\",\n",
      "  \"model_load_mode\": \"from_transformers\",\n",
      "  \"do_train\": true,\n",
      "  \"do_val\": true,\n",
      "  \"do_save\": false,\n",
      "  \"do_save_last\": false,\n",
      "  \"do_save_best\": false,\n",
      "  \"write_val_preds\": false,\n",
      "  \"write_test_preds\": false,\n",
      "  \"eval_every_steps\": 0,\n",
      "  \"save_every_steps\": 0,\n",
      "  \"save_checkpoint_every_steps\": 0,\n",
      "  \"no_improvements_for_n_evals\": 0,\n",
      "  \"keep_checkpoint_when_done\": false,\n",
      "  \"force_overwrite\": false,\n",
      "  \"seed\": 1712373767,\n",
      "  \"learning_rate\": 1e-05,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"optimizer_type\": \"adam\",\n",
      "  \"no_cuda\": false,\n",
      "  \"fp16\": false,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"local_rank\": -1,\n",
      "  \"server_ip\": \"\",\n",
      "  \"server_port\": \"\"\n",
      "}\n",
      "1\n",
      "Creating Tasks:\n",
      "    mnli (MnliTask): ./jiant/jiant/exp/tasks/configs/mnli_config.json\n",
      "No optimizer decay for:\n",
      "  encoder.embeddings.LayerNorm.weight\n",
      "  encoder.embeddings.LayerNorm.bias\n",
      "  encoder.encoder.layer.0.attention.self.query.bias\n",
      "  encoder.encoder.layer.0.attention.self.key.bias\n",
      "  encoder.encoder.layer.0.attention.self.value.bias\n",
      "  encoder.encoder.layer.0.attention.output.dense.bias\n",
      "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.0.intermediate.dense.bias\n",
      "  encoder.encoder.layer.0.output.dense.bias\n",
      "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.1.attention.self.query.bias\n",
      "  encoder.encoder.layer.1.attention.self.key.bias\n",
      "  encoder.encoder.layer.1.attention.self.value.bias\n",
      "  encoder.encoder.layer.1.attention.output.dense.bias\n",
      "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.1.intermediate.dense.bias\n",
      "  encoder.encoder.layer.1.output.dense.bias\n",
      "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.2.attention.self.query.bias\n",
      "  encoder.encoder.layer.2.attention.self.key.bias\n",
      "  encoder.encoder.layer.2.attention.self.value.bias\n",
      "  encoder.encoder.layer.2.attention.output.dense.bias\n",
      "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.2.intermediate.dense.bias\n",
      "  encoder.encoder.layer.2.output.dense.bias\n",
      "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.3.attention.self.query.bias\n",
      "  encoder.encoder.layer.3.attention.self.key.bias\n",
      "  encoder.encoder.layer.3.attention.self.value.bias\n",
      "  encoder.encoder.layer.3.attention.output.dense.bias\n",
      "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.3.intermediate.dense.bias\n",
      "  encoder.encoder.layer.3.output.dense.bias\n",
      "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.4.attention.self.query.bias\n",
      "  encoder.encoder.layer.4.attention.self.key.bias\n",
      "  encoder.encoder.layer.4.attention.self.value.bias\n",
      "  encoder.encoder.layer.4.attention.output.dense.bias\n",
      "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.4.intermediate.dense.bias\n",
      "  encoder.encoder.layer.4.output.dense.bias\n",
      "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.5.attention.self.query.bias\n",
      "  encoder.encoder.layer.5.attention.self.key.bias\n",
      "  encoder.encoder.layer.5.attention.self.value.bias\n",
      "  encoder.encoder.layer.5.attention.output.dense.bias\n",
      "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.5.intermediate.dense.bias\n",
      "  encoder.encoder.layer.5.output.dense.bias\n",
      "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.6.attention.self.query.bias\n",
      "  encoder.encoder.layer.6.attention.self.key.bias\n",
      "  encoder.encoder.layer.6.attention.self.value.bias\n",
      "  encoder.encoder.layer.6.attention.output.dense.bias\n",
      "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.6.intermediate.dense.bias\n",
      "  encoder.encoder.layer.6.output.dense.bias\n",
      "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.7.attention.self.query.bias\n",
      "  encoder.encoder.layer.7.attention.self.key.bias\n",
      "  encoder.encoder.layer.7.attention.self.value.bias\n",
      "  encoder.encoder.layer.7.attention.output.dense.bias\n",
      "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.7.intermediate.dense.bias\n",
      "  encoder.encoder.layer.7.output.dense.bias\n",
      "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.8.attention.self.query.bias\n",
      "  encoder.encoder.layer.8.attention.self.key.bias\n",
      "  encoder.encoder.layer.8.attention.self.value.bias\n",
      "  encoder.encoder.layer.8.attention.output.dense.bias\n",
      "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.8.intermediate.dense.bias\n",
      "  encoder.encoder.layer.8.output.dense.bias\n",
      "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.9.attention.self.query.bias\n",
      "  encoder.encoder.layer.9.attention.self.key.bias\n",
      "  encoder.encoder.layer.9.attention.self.value.bias\n",
      "  encoder.encoder.layer.9.attention.output.dense.bias\n",
      "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.9.intermediate.dense.bias\n",
      "  encoder.encoder.layer.9.output.dense.bias\n",
      "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.10.attention.self.query.bias\n",
      "  encoder.encoder.layer.10.attention.self.key.bias\n",
      "  encoder.encoder.layer.10.attention.self.value.bias\n",
      "  encoder.encoder.layer.10.attention.output.dense.bias\n",
      "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.10.intermediate.dense.bias\n",
      "  encoder.encoder.layer.10.output.dense.bias\n",
      "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.11.attention.self.query.bias\n",
      "  encoder.encoder.layer.11.attention.self.key.bias\n",
      "  encoder.encoder.layer.11.attention.self.value.bias\n",
      "  encoder.encoder.layer.11.attention.output.dense.bias\n",
      "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.11.intermediate.dense.bias\n",
      "  encoder.encoder.layer.11.output.dense.bias\n",
      "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
      "  encoder.pooler.dense.bias\n",
      "  taskmodels_dict.mnli.classification_head.dense.bias\n",
      "  taskmodels_dict.mnli.classification_head.out_proj.bias\n",
      "Using AdamW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acea8d67d8a44d64956bc6c4b2ce0827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=392702.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c579aa959013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/simple/runscript.py\u001b[0m in \u001b[0;36mrun_simple\u001b[0;34m(args, with_continue)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mrunscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mpy_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"simple_run_config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/runscript.py\u001b[0m in \u001b[0;36mrun_loop\u001b[0;34m(args, checkpoint)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mmetarunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metarunner_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metarunner_state\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mmetarunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/shared/metarunner.py\u001b[0m in \u001b[0;36mrun_train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myield_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/metarunner.py\u001b[0m in \u001b[0;36myield_train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mtrain_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             )\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_at_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/runner.py\u001b[0m in \u001b[0;36mrun_train_context\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         ):\n\u001b[0;32m---> 75\u001b[0;31m             self.run_train_step(\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mtrain_dataloader_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             )\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/runner.py\u001b[0m in \u001b[0;36mrun_train_step\u001b[0;34m(self, train_dataloader_dict, train_state)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             model_output = wrap_jiant_forward(\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mjiant_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjiant_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             )\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/modeling/primary.py\u001b[0m in \u001b[0;36mwrap_jiant_forward\u001b[0;34m(jiant_model, batch, task, compute_loss)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mis_multi_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjiant_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     model_output = construct_output_from_dict(\n\u001b[0;32m---> 81\u001b[0;31m         jiant_model(\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_multi_gpu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/modeling/primary.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, task, compute_loss)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mtaskmodel_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_to_taskmodel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtaskmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaskmodels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtaskmodel_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         return taskmodel(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         ).to_dict()\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/modeling/taskmodels.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, task, tokenizer, compute_loss)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_output_from_encoder_and_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/modeling/taskmodels.py\u001b[0m in \u001b[0;36mget_output_from_encoder_and_batch\u001b[0;34m(encoder, batch)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \"\"\"\n\u001b[0;32m--> 281\u001b[0;31m     return get_output_from_encoder(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/modeling/taskmodels.py\u001b[0m in \u001b[0;36mget_output_from_encoder\u001b[0;34m(encoder, input_ids, segment_ids, input_mask)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mModelArchitectures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXLM_ROBERTA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     ]:\n\u001b[0;32m--> 312\u001b[0;31m         pooled, unpooled, other = get_output_from_standard_transformer_models(\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         )\n",
      "\u001b[0;32m~/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/proj/main/modeling/taskmodels.py\u001b[0m in \u001b[0;36mget_output_from_standard_transformer_models\u001b[0;34m(encoder, input_ids, segment_ids, input_mask)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_output_from_standard_transformer_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \u001b[0mpooled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpooled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpooled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpooled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         )\n\u001b[0;32m--> 827\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 )\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    485\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     ):\n\u001b[0;32m--> 408\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     ):\n\u001b[0;32m--> 343\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     ):\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "run.run_simple(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MRPC Test (English)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2. Data 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:55:41.509621Z",
     "start_time": "2021-03-28T12:55:38.886064Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/seongtae/.cache/huggingface/datasets/glue/mrpc/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and generated configs for 'mrpc' (1/1)\n"
     ]
    }
   ],
   "source": [
    "downloader.download_data([\"mrpc\"], f\"{EXP_DIR}/tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3. Configuration argument 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T12:55:41.514363Z",
     "start_time": "2021-03-28T12:55:41.511215Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = run.RunConfiguration(\n",
    "   run_name=\"simple\",\n",
    "   exp_dir=EXP_DIR,\n",
    "   data_dir=f\"{EXP_DIR}/tasks\",\n",
    "   hf_pretrained_model_name_or_path=\"roberta-base\", # transformers.Autoconfig에 등록된 모든 모델들 및 경로 지정 후 따로 사용 가능\n",
    "   tasks=\"mrpc\",\n",
    "   train_batch_size=2,\n",
    "   num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 4. 벤치마크 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:18:28.254397Z",
     "start_time": "2021-03-28T12:55:41.516234Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running from start\n",
      "  jiant_task_container_config_path: ./jiant/jiant/exp/run_configs/simple_config.json\n",
      "  output_dir: ./jiant/jiant/exp/runs/simple\n",
      "  hf_pretrained_model_name_or_path: roberta-base\n",
      "  model_path: ./jiant/jiant/exp/models/roberta/model/model.p\n",
      "  model_config_path: ./jiant/jiant/exp/models/roberta/model/config.json\n",
      "  model_load_mode: from_transformers\n",
      "  do_train: True\n",
      "  do_val: True\n",
      "  do_save: False\n",
      "  do_save_last: False\n",
      "  do_save_best: False\n",
      "  write_val_preds: False\n",
      "  write_test_preds: False\n",
      "  eval_every_steps: 0\n",
      "  save_every_steps: 0\n",
      "  save_checkpoint_every_steps: 0\n",
      "  no_improvements_for_n_evals: 0\n",
      "  keep_checkpoint_when_done: False\n",
      "  force_overwrite: False\n",
      "  seed: -1\n",
      "  learning_rate: 1e-05\n",
      "  adam_epsilon: 1e-08\n",
      "  max_grad_norm: 1.0\n",
      "  optimizer_type: adam\n",
      "  no_cuda: False\n",
      "  fp16: False\n",
      "  fp16_opt_level: O1\n",
      "  local_rank: -1\n",
      "  server_ip: \n",
      "  server_port: \n",
      "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "Using seed: 1324150901\n",
      "{\n",
      "  \"jiant_task_container_config_path\": \"./jiant/jiant/exp/run_configs/simple_config.json\",\n",
      "  \"output_dir\": \"./jiant/jiant/exp/runs/simple\",\n",
      "  \"hf_pretrained_model_name_or_path\": \"roberta-base\",\n",
      "  \"model_path\": \"./jiant/jiant/exp/models/roberta/model/model.p\",\n",
      "  \"model_config_path\": \"./jiant/jiant/exp/models/roberta/model/config.json\",\n",
      "  \"model_load_mode\": \"from_transformers\",\n",
      "  \"do_train\": true,\n",
      "  \"do_val\": true,\n",
      "  \"do_save\": false,\n",
      "  \"do_save_last\": false,\n",
      "  \"do_save_best\": false,\n",
      "  \"write_val_preds\": false,\n",
      "  \"write_test_preds\": false,\n",
      "  \"eval_every_steps\": 0,\n",
      "  \"save_every_steps\": 0,\n",
      "  \"save_checkpoint_every_steps\": 0,\n",
      "  \"no_improvements_for_n_evals\": 0,\n",
      "  \"keep_checkpoint_when_done\": false,\n",
      "  \"force_overwrite\": false,\n",
      "  \"seed\": 1324150901,\n",
      "  \"learning_rate\": 1e-05,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"optimizer_type\": \"adam\",\n",
      "  \"no_cuda\": false,\n",
      "  \"fp16\": false,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"local_rank\": -1,\n",
      "  \"server_ip\": \"\",\n",
      "  \"server_port\": \"\"\n",
      "}\n",
      "1\n",
      "Creating Tasks:\n",
      "    mrpc (MrpcTask): ./jiant/jiant/exp/tasks/configs/mrpc_config.json\n",
      "No optimizer decay for:\n",
      "  encoder.embeddings.LayerNorm.weight\n",
      "  encoder.embeddings.LayerNorm.bias\n",
      "  encoder.encoder.layer.0.attention.self.query.bias\n",
      "  encoder.encoder.layer.0.attention.self.key.bias\n",
      "  encoder.encoder.layer.0.attention.self.value.bias\n",
      "  encoder.encoder.layer.0.attention.output.dense.bias\n",
      "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.0.intermediate.dense.bias\n",
      "  encoder.encoder.layer.0.output.dense.bias\n",
      "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.1.attention.self.query.bias\n",
      "  encoder.encoder.layer.1.attention.self.key.bias\n",
      "  encoder.encoder.layer.1.attention.self.value.bias\n",
      "  encoder.encoder.layer.1.attention.output.dense.bias\n",
      "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.1.intermediate.dense.bias\n",
      "  encoder.encoder.layer.1.output.dense.bias\n",
      "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.2.attention.self.query.bias\n",
      "  encoder.encoder.layer.2.attention.self.key.bias\n",
      "  encoder.encoder.layer.2.attention.self.value.bias\n",
      "  encoder.encoder.layer.2.attention.output.dense.bias\n",
      "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.2.intermediate.dense.bias\n",
      "  encoder.encoder.layer.2.output.dense.bias\n",
      "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.3.attention.self.query.bias\n",
      "  encoder.encoder.layer.3.attention.self.key.bias\n",
      "  encoder.encoder.layer.3.attention.self.value.bias\n",
      "  encoder.encoder.layer.3.attention.output.dense.bias\n",
      "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.3.intermediate.dense.bias\n",
      "  encoder.encoder.layer.3.output.dense.bias\n",
      "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.4.attention.self.query.bias\n",
      "  encoder.encoder.layer.4.attention.self.key.bias\n",
      "  encoder.encoder.layer.4.attention.self.value.bias\n",
      "  encoder.encoder.layer.4.attention.output.dense.bias\n",
      "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.4.intermediate.dense.bias\n",
      "  encoder.encoder.layer.4.output.dense.bias\n",
      "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.5.attention.self.query.bias\n",
      "  encoder.encoder.layer.5.attention.self.key.bias\n",
      "  encoder.encoder.layer.5.attention.self.value.bias\n",
      "  encoder.encoder.layer.5.attention.output.dense.bias\n",
      "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.5.intermediate.dense.bias\n",
      "  encoder.encoder.layer.5.output.dense.bias\n",
      "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.6.attention.self.query.bias\n",
      "  encoder.encoder.layer.6.attention.self.key.bias\n",
      "  encoder.encoder.layer.6.attention.self.value.bias\n",
      "  encoder.encoder.layer.6.attention.output.dense.bias\n",
      "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.6.intermediate.dense.bias\n",
      "  encoder.encoder.layer.6.output.dense.bias\n",
      "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.7.attention.self.query.bias\n",
      "  encoder.encoder.layer.7.attention.self.key.bias\n",
      "  encoder.encoder.layer.7.attention.self.value.bias\n",
      "  encoder.encoder.layer.7.attention.output.dense.bias\n",
      "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.7.intermediate.dense.bias\n",
      "  encoder.encoder.layer.7.output.dense.bias\n",
      "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.8.attention.self.query.bias\n",
      "  encoder.encoder.layer.8.attention.self.key.bias\n",
      "  encoder.encoder.layer.8.attention.self.value.bias\n",
      "  encoder.encoder.layer.8.attention.output.dense.bias\n",
      "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.8.intermediate.dense.bias\n",
      "  encoder.encoder.layer.8.output.dense.bias\n",
      "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.9.attention.self.query.bias\n",
      "  encoder.encoder.layer.9.attention.self.key.bias\n",
      "  encoder.encoder.layer.9.attention.self.value.bias\n",
      "  encoder.encoder.layer.9.attention.output.dense.bias\n",
      "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.9.intermediate.dense.bias\n",
      "  encoder.encoder.layer.9.output.dense.bias\n",
      "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.10.attention.self.query.bias\n",
      "  encoder.encoder.layer.10.attention.self.key.bias\n",
      "  encoder.encoder.layer.10.attention.self.value.bias\n",
      "  encoder.encoder.layer.10.attention.output.dense.bias\n",
      "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.10.intermediate.dense.bias\n",
      "  encoder.encoder.layer.10.output.dense.bias\n",
      "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.11.attention.self.query.bias\n",
      "  encoder.encoder.layer.11.attention.self.key.bias\n",
      "  encoder.encoder.layer.11.attention.self.value.bias\n",
      "  encoder.encoder.layer.11.attention.output.dense.bias\n",
      "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.11.intermediate.dense.bias\n",
      "  encoder.encoder.layer.11.output.dense.bias\n",
      "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
      "  encoder.pooler.dense.bias\n",
      "  taskmodels_dict.mrpc.classification_head.dense.bias\n",
      "  taskmodels_dict.mrpc.classification_head.out_proj.bias\n",
      "Using AdamW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a4f98508ec4f83a20971c93737fa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=5502.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d223265f42d54ae7b58c98de7c5ee687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval (mrpc, Val)', max=102.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00580c80a4c4efeab5d82d783307e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval (mrpc, Val)', max=102.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Best\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adca7a20035e418190899fa6ca53ea01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval (mrpc, Val)', max=102.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"aggregated\": 0.8876429373180399,\n",
      "  \"mrpc\": {\n",
      "    \"loss\": 0.7550861622365511,\n",
      "    \"metrics\": {\n",
      "      \"major\": 0.8876429373180399,\n",
      "      \"minor\": {\n",
      "        \"acc\": 0.8700980392156863,\n",
      "        \"f1\": 0.9051878354203935,\n",
      "        \"acc_and_f1\": 0.8876429373180399\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "run.run_simple(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# STS-B Test (Korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T13:59:36.335249Z",
     "start_time": "2021-03-28T13:59:36.331027Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "EXP_DIR = \"./jiant/jiant/exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T15:13:59.115032Z",
     "start_time": "2021-03-28T15:13:59.112168Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "args = run.RunConfiguration(\n",
    "   run_name=\"simple\",\n",
    "   exp_dir=EXP_DIR,\n",
    "   data_dir=f\"{EXP_DIR}/tasks\",\n",
    "   hf_pretrained_model_name_or_path=\"monologg/kobert\", # transformers.Autoconfig에 등록된 모든 모델들 및 경로 지정 후 따로 사용 가능\n",
    "   tasks=\"stsb\",\n",
    "   train_batch_size=2,\n",
    "   num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T16:11:41.054963Z",
     "start_time": "2021-03-28T15:14:02.748675Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87505361537e456995d517f743831063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=389.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa2a12978fd496bbbc4a358fe44aa12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=397106539.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForPreTraining were not initialized from the model checkpoint at snunlp/KR-BERT-char16424 and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7799f1eb974bffb02534f326d97898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=103847.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing Task 'stsb' for phases 'train,val,test'\n",
      "StsbTask\n",
      "  [train]: /home/seongtae/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/exp/tasks/data/korsts/train.jsonl\n",
      "  [test]: /home/seongtae/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/exp/tasks/data/korsts/test.jsonl\n",
      "  [val]: /home/seongtae/insync/Synology/Seongtae/Drive/SIRE/Projects/GLUE_20210330/jiant/jiant/exp/tasks/data/korsts/val.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65781f3f62e74de491d8ef1de23fa591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Tokenizing', max=5749.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1577a8f15e5640c1a8e7605b24fd2c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Smart truncate chunks', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa50c03dd8ed4e2589e04448f2e99ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Smart truncate chunk-datum', max=5749.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ad90062eed4602bae38205b2ed97a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Tokenizing', max=1500.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcdc753156a4cf2841f31aa528673de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Smart truncate chunks', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da3f191e4b34d33b6682316faf0cf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Smart truncate chunk-datum', max=1500.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3618c00dde694301a6a587c7ea641a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Tokenizing', max=1379.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02f28c5556c4a82b8b6c36b31e5b4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Smart truncate chunks', max=1.0, style=ProgressStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bbb58b4bb74fcca06cb314d041cc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Smart truncate chunk-datum', max=1379.0, style=ProgressSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running from start\n",
      "  jiant_task_container_config_path: ./jiant/jiant/exp/run_configs/simple_config.json\n",
      "  output_dir: ./jiant/jiant/exp/runs/simple\n",
      "  hf_pretrained_model_name_or_path: snunlp/KR-BERT-char16424\n",
      "  model_path: ./jiant/jiant/exp/models/bert/model/model.p\n",
      "  model_config_path: ./jiant/jiant/exp/models/bert/model/config.json\n",
      "  model_load_mode: from_transformers\n",
      "  do_train: True\n",
      "  do_val: True\n",
      "  do_save: False\n",
      "  do_save_last: False\n",
      "  do_save_best: False\n",
      "  write_val_preds: False\n",
      "  write_test_preds: False\n",
      "  eval_every_steps: 0\n",
      "  save_every_steps: 0\n",
      "  save_checkpoint_every_steps: 0\n",
      "  no_improvements_for_n_evals: 0\n",
      "  keep_checkpoint_when_done: False\n",
      "  force_overwrite: False\n",
      "  seed: -1\n",
      "  learning_rate: 1e-05\n",
      "  adam_epsilon: 1e-08\n",
      "  max_grad_norm: 1.0\n",
      "  optimizer_type: adam\n",
      "  no_cuda: False\n",
      "  fp16: False\n",
      "  fp16_opt_level: O1\n",
      "  local_rank: -1\n",
      "  server_ip: \n",
      "  server_port: \n",
      "device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "Using seed: 316954341\n",
      "{\n",
      "  \"jiant_task_container_config_path\": \"./jiant/jiant/exp/run_configs/simple_config.json\",\n",
      "  \"output_dir\": \"./jiant/jiant/exp/runs/simple\",\n",
      "  \"hf_pretrained_model_name_or_path\": \"snunlp/KR-BERT-char16424\",\n",
      "  \"model_path\": \"./jiant/jiant/exp/models/bert/model/model.p\",\n",
      "  \"model_config_path\": \"./jiant/jiant/exp/models/bert/model/config.json\",\n",
      "  \"model_load_mode\": \"from_transformers\",\n",
      "  \"do_train\": true,\n",
      "  \"do_val\": true,\n",
      "  \"do_save\": false,\n",
      "  \"do_save_last\": false,\n",
      "  \"do_save_best\": false,\n",
      "  \"write_val_preds\": false,\n",
      "  \"write_test_preds\": false,\n",
      "  \"eval_every_steps\": 0,\n",
      "  \"save_every_steps\": 0,\n",
      "  \"save_checkpoint_every_steps\": 0,\n",
      "  \"no_improvements_for_n_evals\": 0,\n",
      "  \"keep_checkpoint_when_done\": false,\n",
      "  \"force_overwrite\": false,\n",
      "  \"seed\": 316954341,\n",
      "  \"learning_rate\": 1e-05,\n",
      "  \"adam_epsilon\": 1e-08,\n",
      "  \"max_grad_norm\": 1.0,\n",
      "  \"optimizer_type\": \"adam\",\n",
      "  \"no_cuda\": false,\n",
      "  \"fp16\": false,\n",
      "  \"fp16_opt_level\": \"O1\",\n",
      "  \"local_rank\": -1,\n",
      "  \"server_ip\": \"\",\n",
      "  \"server_port\": \"\"\n",
      "}\n",
      "1\n",
      "Creating Tasks:\n",
      "    stsb (StsbTask): ./jiant/jiant/exp/tasks/configs/stsb_config.json\n",
      "No optimizer decay for:\n",
      "  encoder.embeddings.LayerNorm.weight\n",
      "  encoder.embeddings.LayerNorm.bias\n",
      "  encoder.encoder.layer.0.attention.self.query.bias\n",
      "  encoder.encoder.layer.0.attention.self.key.bias\n",
      "  encoder.encoder.layer.0.attention.self.value.bias\n",
      "  encoder.encoder.layer.0.attention.output.dense.bias\n",
      "  encoder.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.0.intermediate.dense.bias\n",
      "  encoder.encoder.layer.0.output.dense.bias\n",
      "  encoder.encoder.layer.0.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.0.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.1.attention.self.query.bias\n",
      "  encoder.encoder.layer.1.attention.self.key.bias\n",
      "  encoder.encoder.layer.1.attention.self.value.bias\n",
      "  encoder.encoder.layer.1.attention.output.dense.bias\n",
      "  encoder.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.1.intermediate.dense.bias\n",
      "  encoder.encoder.layer.1.output.dense.bias\n",
      "  encoder.encoder.layer.1.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.1.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.2.attention.self.query.bias\n",
      "  encoder.encoder.layer.2.attention.self.key.bias\n",
      "  encoder.encoder.layer.2.attention.self.value.bias\n",
      "  encoder.encoder.layer.2.attention.output.dense.bias\n",
      "  encoder.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.2.intermediate.dense.bias\n",
      "  encoder.encoder.layer.2.output.dense.bias\n",
      "  encoder.encoder.layer.2.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.2.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.3.attention.self.query.bias\n",
      "  encoder.encoder.layer.3.attention.self.key.bias\n",
      "  encoder.encoder.layer.3.attention.self.value.bias\n",
      "  encoder.encoder.layer.3.attention.output.dense.bias\n",
      "  encoder.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.3.intermediate.dense.bias\n",
      "  encoder.encoder.layer.3.output.dense.bias\n",
      "  encoder.encoder.layer.3.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.3.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.4.attention.self.query.bias\n",
      "  encoder.encoder.layer.4.attention.self.key.bias\n",
      "  encoder.encoder.layer.4.attention.self.value.bias\n",
      "  encoder.encoder.layer.4.attention.output.dense.bias\n",
      "  encoder.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.4.intermediate.dense.bias\n",
      "  encoder.encoder.layer.4.output.dense.bias\n",
      "  encoder.encoder.layer.4.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.4.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.5.attention.self.query.bias\n",
      "  encoder.encoder.layer.5.attention.self.key.bias\n",
      "  encoder.encoder.layer.5.attention.self.value.bias\n",
      "  encoder.encoder.layer.5.attention.output.dense.bias\n",
      "  encoder.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.5.intermediate.dense.bias\n",
      "  encoder.encoder.layer.5.output.dense.bias\n",
      "  encoder.encoder.layer.5.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.5.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.6.attention.self.query.bias\n",
      "  encoder.encoder.layer.6.attention.self.key.bias\n",
      "  encoder.encoder.layer.6.attention.self.value.bias\n",
      "  encoder.encoder.layer.6.attention.output.dense.bias\n",
      "  encoder.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.6.intermediate.dense.bias\n",
      "  encoder.encoder.layer.6.output.dense.bias\n",
      "  encoder.encoder.layer.6.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.6.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.7.attention.self.query.bias\n",
      "  encoder.encoder.layer.7.attention.self.key.bias\n",
      "  encoder.encoder.layer.7.attention.self.value.bias\n",
      "  encoder.encoder.layer.7.attention.output.dense.bias\n",
      "  encoder.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.7.intermediate.dense.bias\n",
      "  encoder.encoder.layer.7.output.dense.bias\n",
      "  encoder.encoder.layer.7.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.7.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.8.attention.self.query.bias\n",
      "  encoder.encoder.layer.8.attention.self.key.bias\n",
      "  encoder.encoder.layer.8.attention.self.value.bias\n",
      "  encoder.encoder.layer.8.attention.output.dense.bias\n",
      "  encoder.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.8.intermediate.dense.bias\n",
      "  encoder.encoder.layer.8.output.dense.bias\n",
      "  encoder.encoder.layer.8.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.8.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.9.attention.self.query.bias\n",
      "  encoder.encoder.layer.9.attention.self.key.bias\n",
      "  encoder.encoder.layer.9.attention.self.value.bias\n",
      "  encoder.encoder.layer.9.attention.output.dense.bias\n",
      "  encoder.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.9.intermediate.dense.bias\n",
      "  encoder.encoder.layer.9.output.dense.bias\n",
      "  encoder.encoder.layer.9.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.9.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.10.attention.self.query.bias\n",
      "  encoder.encoder.layer.10.attention.self.key.bias\n",
      "  encoder.encoder.layer.10.attention.self.value.bias\n",
      "  encoder.encoder.layer.10.attention.output.dense.bias\n",
      "  encoder.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.10.intermediate.dense.bias\n",
      "  encoder.encoder.layer.10.output.dense.bias\n",
      "  encoder.encoder.layer.10.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.10.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.11.attention.self.query.bias\n",
      "  encoder.encoder.layer.11.attention.self.key.bias\n",
      "  encoder.encoder.layer.11.attention.self.value.bias\n",
      "  encoder.encoder.layer.11.attention.output.dense.bias\n",
      "  encoder.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "  encoder.encoder.layer.11.intermediate.dense.bias\n",
      "  encoder.encoder.layer.11.output.dense.bias\n",
      "  encoder.encoder.layer.11.output.LayerNorm.weight\n",
      "  encoder.encoder.layer.11.output.LayerNorm.bias\n",
      "  encoder.pooler.dense.bias\n",
      "  taskmodels_dict.stsb.regression_head.dense.bias\n",
      "  taskmodels_dict.stsb.regression_head.out_proj.bias\n",
      "Using AdamW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83545e7cff14632ac66ef7f4da64af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=8625.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d68d438efc4e37a1cdeded0b5b71c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval (stsb, Val)', max=125.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04346e8d98f34c12873c015c4843dc99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval (stsb, Val)', max=125.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Best\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6127c1ce7cb4d6f91d31efc41b2a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Eval (stsb, Val)', max=375.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"aggregated\": 0.507746337147401,\n",
      "  \"stsb\": {\n",
      "    \"loss\": 1.9573405211269856,\n",
      "    \"metrics\": {\n",
      "      \"major\": 0.507746337147401,\n",
      "      \"minor\": {\n",
      "        \"pearson\": 0.4890125965524699,\n",
      "        \"spearmanr\": 0.5264800777423322,\n",
      "        \"corr\": 0.507746337147401\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "run.run_simple(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SUPER-GLUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T04:22:54.890182Z",
     "start_time": "2021-03-29T04:22:44.744875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "downloader.download_data([\"cb\"], f\"{EXP_DIR}/tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
