{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch2_final.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hZSxa1k9mG0T","colab_type":"text"},"source":["# 1. 사전작업\n","setup.sh 업로드 후 실행해 주세요."]},{"cell_type":"code","metadata":{"id":"Ucm9kKNUmGWg","colab_type":"code","outputId":"51882e14-d485-42ee-c002-85f5839f4ee1","executionInfo":{"status":"ok","timestamp":1579503224033,"user_tz":-540,"elapsed":171124,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! bash setup.sh"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Installing openjdk-8-jdk....\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n","  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jre x11-utils\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin mesa-utils\n","The following NEW packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n","  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jre x11-utils\n","0 upgraded, 8 newly installed, 0 to remove and 7 not upgraded.\n","Need to get 4,954 kB of archives.\n","After this operation, 13.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u232-b09-0ubuntu1~18.04.1 [69.8 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u232-b09-0ubuntu1~18.04.1 [1,618 kB]\n","Fetched 4,954 kB in 1s (5,259 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 8.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libxxf86dga1:amd64.\n","(Reading database ... 145674 files and directories currently installed.)\n","Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Selecting previously unselected package fonts-dejavu-core.\n","Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-1) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n","Unpacking x11-utils (7.7+3build1) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n","Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n","Selecting previously unselected package openjdk-8-jre:amd64.\n","Preparing to unpack .../6-openjdk-8-jre_8u232-b09-0ubuntu1~18.04.1_amd64.deb ...\n","Unpacking openjdk-8-jre:amd64 (8u232-b09-0ubuntu1~18.04.1) ...\n","Selecting previously unselected package openjdk-8-jdk:amd64.\n","Preparing to unpack .../7-openjdk-8-jdk_8u232-b09-0ubuntu1~18.04.1_amd64.deb ...\n","Unpacking openjdk-8-jdk:amd64 (8u232-b09-0ubuntu1~18.04.1) ...\n","Setting up fonts-dejavu-core (2.37-1) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Setting up fonts-dejavu-extra (2.37-1) ...\n","Setting up x11-utils (7.7+3build1) ...\n","Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n","Setting up openjdk-8-jre:amd64 (8u232-b09-0ubuntu1~18.04.1) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n","Setting up openjdk-8-jdk:amd64 (8u232-b09-0ubuntu1~18.04.1) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","Done\n","Installing Spacy\n","Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n","Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n","Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n","Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n","Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.6/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Done\n","Installing nltk\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n","Done\n","Installing konlpy.....\n","Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 161kB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/90/a94a55a58edfd67360fef85894bfb136a2c28b2cc7227d3a44dc508d5900/JPype1-0.7.1-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 59.5MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.8MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n","Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n","Installing collected packages: JPype1, colorama, tweepy, beautifulsoup4, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-0.7.1 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n","Done\n","Installing JPype1-py3....\n","Collecting JPype1-py3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 2.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n","  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2662193 sha256=d5d4ec281232d3dea54442b8192656b55853b6d004b2572aba20ce37a320d74b\n","  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n","Successfully built JPype1-py3\n","Installing collected packages: JPype1-py3\n","Successfully installed JPype1-py3-0.5.5.4\n","setup.sh: line 24: echoDone: command not found\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2020-01-20 06:51:56--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...\n","Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=kE3HDHmfSoQ2Pp%2BeLKy6QwpTiIA%3D&Expires=1579503829&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n","--2020-01-20 06:51:56--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=kE3HDHmfSoQ2Pp%2BeLKy6QwpTiIA%3D&Expires=1579503829&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.47.156\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.47.156|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.08s   \n","\n","2020-01-20 06:51:56 (17.6 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2020-01-20 06:53:14--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...\n","Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=lC9Gku2aTFy%2B67SkVAdVfV0fGaM%3D&Expires=1579503910&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n","--2020-01-20 06:53:14--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=lC9Gku2aTFy%2B67SkVAdVfV0fGaM%3D&Expires=1579503910&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.184.75\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.184.75|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  98.5MB/s    in 0.5s    \n","\n","2020-01-20 06:53:15 (98.5 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","apt install curl\n","apt install git\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n","Done\n","Getting nsmc contents\n","Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 22.74 MiB/s, done.\n","Resolving deltas: 100% (1749/1749), done.\n","Checking out files: 100% (14737/14737), done.\n","Done\n","Setup Finished!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HPDUFgz6bi7l","colab_type":"text"},"source":["# 2. 자연어처리의 기본"]},{"cell_type":"markdown","metadata":{"id":"fYV65JkhglFl","colab_type":"text"},"source":["## Spacy를 사용하여 토큰을 분리하기"]},{"cell_type":"code","metadata":{"id":"ffH2jwdjgpEE","colab_type":"code","outputId":"9a1f5f35-cac7-46b8-e8f9-dd689db58c3e","executionInfo":{"status":"error","timestamp":1579503768337,"user_tz":-540,"elapsed":670,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":310}},"source":["import spacy\n","chomsky = \"Colorless green ideas sleep furiously\"\n","spacy_en = spacy.load('en')\n","\n","def tokenize_en(text):\n","  return [tok.text for tok in spacy_en.tokenizer(text)]\n","print(tokenize_en(chomsky))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-46de9def9cfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchomsky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Colorless green ideas sleep furiously\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspacy_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_en\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# in data dir / shortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# installed as package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_link\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE051\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/data/en/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, **overrides)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# language subclass) while keeping top-level language identifier \"lang\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lang_factory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lang\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lang_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mget_lang_class\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLANGUAGES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".lang.%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"spacy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE048\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/lang/en/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBASE_EXCEPTIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_exceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBASE_NORMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mlanguage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLANG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNORM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mupdate_exc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_lookups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msrsly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlemmatizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLemmatizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/tokenizer.cpython-36m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36minit spacy.tokenizer\u001b[0;34m()\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: type object 'spacy.tokenizer.array' has no attribute '__reduce_cython__'"]}]},{"cell_type":"markdown","metadata":{"id":"ybJUYPOSiBSV","colab_type":"text"},"source":["## NLTK를 사용하여 토큰을 분리하기"]},{"cell_type":"code","metadata":{"id":"SfW_iFl6hZRM","colab_type":"code","outputId":"63ae0913-2fc2-4c63-e0fd-4ca959ba0780","executionInfo":{"status":"ok","timestamp":1579503247748,"user_tz":-540,"elapsed":2044,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","print(word_tokenize(chomsky))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","['Colorless', 'green', 'ideas', 'sleep', 'furiously']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AK-2j6a2iFpr","colab_type":"text"},"source":["## python의 기본 함수 split()을 이용하여 토큰을 분리하기"]},{"cell_type":"code","metadata":{"id":"aVGCx5VriOWo","colab_type":"code","outputId":"c84fdd44-de66-45c3-f692-82373a50ffb4","executionInfo":{"status":"ok","timestamp":1579503254311,"user_tz":-540,"elapsed":803,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(chomsky.split())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['Colorless', 'green', 'ideas', 'sleep', 'furiously']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-tvcPOWEil79","colab_type":"text"},"source":["## Konlpy로 한국어를 처리하기"]},{"cell_type":"code","metadata":{"id":"2CpOoFE0bQZY","colab_type":"code","outputId":"6cc7662d-d867-42ec-a906-c93743babbdb","executionInfo":{"status":"ok","timestamp":1579503258830,"user_tz":-540,"elapsed":826,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["from konlpy.tag import Mecab\n","\n","kor_sentence = \"펭수를 보아라. 행복해질 것이니\"\n","tokenizer = Mecab()\n","\n","tokenized_sent = tokenizer.pos(kor_sentence)\n","print(tokenized_sent)\n","print([(k, tokenizer.tagset.get(v)) for k, v in tokenized_sent])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[('펭', 'NNG'), ('수', 'NNG'), ('를', 'JKO'), ('보', 'VV'), ('아라', 'EF'), ('.', 'SF'), ('행복', 'NNG'), ('해질', 'XSA+EC+VX+ETM'), ('것', 'NNB'), ('이', 'VCP'), ('니', 'EC')]\n","[('펭', '일반 명사'), ('수', '일반 명사'), ('를', '목적격 조사'), ('보', '동사'), ('아라', '종결 어미'), ('.', '마침표, 물음표, 느낌표'), ('행복', '일반 명사'), ('해질', None), ('것', '의존 명사'), ('이', '긍정 지정사'), ('니', '연결 어미')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Alm6EECGkaSi","colab_type":"text"},"source":["## 단어장 만들기"]},{"cell_type":"code","metadata":{"id":"f7x97y_CkToY","colab_type":"code","outputId":"aa7a07f7-9b68-4653-c68a-3a78a392119b","executionInfo":{"status":"ok","timestamp":1579503464002,"user_tz":-540,"elapsed":17565,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["with open(\"./nsmc/ratings.txt\") as file:\n","    raw_data = file.read().splitlines()[1:]\n","    data = [line.split(\"\\t\")[1:] for line in raw_data]\n","    data = [(tokenizer.morphs(sent), int(label)) for (sent, label) in data]\n","    \n","sample_data = data[4:14] + data[-10:]\n","print(sample_data[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(['사랑', '을', '해', '본', '사람', '이', '라면', '처음', '부터', '끝', '까지', '웃', '을', '수', '있', '는', '영화'], 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"llo4BtHalwxf","colab_type":"code","colab":{}},"source":["def build_vocab(data):\n","    flatten = lambda d: [token for sent in d for token in sent] # 이중 리스트 구조를 하나의 리스트 구조로 만들어준다.\n","    vocab = {}\n","    vocab['<unk>'] = 0\n","    vocab['<pad>'] = 1\n","    for token in flatten(list(zip(*data))[0]):\n","        if vocab.get(token) is None:\n","            vocab.setdefault(token, len(vocab))\n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WH4DQKUBl6sw","colab_type":"code","outputId":"d06b4e79-4471-4007-eb57-c9019f39a892","executionInfo":{"status":"ok","timestamp":1579503474867,"user_tz":-540,"elapsed":632,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":513}},"source":["vocab = build_vocab(sample_data)\n","print('{}개의 단어를 단어장에 추가'.format(len(vocab)))\n","\n","def show_vocab(vocab):\n","  i=0\n","  for key, value in vocab.items():\n","    if i >= 5:\n","      print(\"{}{} {}\".format(value, ': ', key))\n","      i=0\n","    else:\n","      print(\"{}{}\\t{}\\t\".format(value, ': ', key), end='')\n","      i += 1\n","show_vocab(vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["157개의 단어를 단어장에 추가\n","0: \t<unk>\t1: \t<pad>\t2: \t안개\t3: \t자욱\t4: \t한\t5:  밤하늘\n","6: \t에\t7: \t떠\t8: \t있\t9: \t는\t10: \t초승달\t11:  같\n","12: \t은\t13: \t영화\t14: \t.\t15: \t사랑\t16: \t을\t17:  해\n","18: \t본\t19: \t사람\t20: \t이\t21: \t라면\t22: \t처음\t23:  부터\n","24: \t끝\t25: \t까지\t26: \t웃\t27: \t수\t28: \t완전\t29:  감동\n","30: \t입니다\t31: \t다시\t32: \t봐도\t33: \t개\t34: \t들\t35:  의\n","36: \t전쟁\t37: \t2\t38: \t나오\t39: \t나요\t40: \t?\t41:  면\n","42: \t1\t43: \t빠\t44: \t로\t45: \t보\t46: \t고\t47:  싶\n","48: \t음\t49: \t굿\t50: \t바보\t51: \t가\t52: \t아니\t53:  라\n","54: \t병\t55: \t쉰\t56: \t인\t57: \t듯\t58: \t내\t59:  나이\n","60: \t와\t61: \t를\t62: \t지금\t63: \t나\t64: \t적\t65:  다\n","66: \t하지만\t67: \t훗날\t68: \t보면대\t69: \t사\t70: \t하나\t71:  그\n","72: \t감정\t73: \t완벽\t74: \t하\t75: \t게\t76: \t이해\t77:  할\n","78: \t것\t79: \t만\t80: \t..\t81: \t재밌\t82: \t고질라\t83:  니무\n","84: \t귀엽\t85: \t능\t86: \tㅋㅋ\t87: \t오페라\t88: \t화\t89:  라고\n","90: \t해야\t91: \t작품\t92: \t극단\t93: \t평갈\t94: \t림\t95:  어쩔\n","96: \t없\t97: \t장르\t98: \t무협\t99: \t인데\t100: \t기\t101:  엔\n","102: \t코믹\t103: \t던데\t104: \t막장\t105: \t평점\t106: \t점\t107:  도\n","108: \t아깝\t109: \t나치\t110: \t입장\t111: \t에서\t112: \t갑자기\t113:  연속\n","114: \t으로\t115: \t네\t116: \t뭔일\t117: \t었\t118: \t태권도\t119:  ??\n","120: \t왜\t121: \t봤\t122: \t을까\t123: \t예고편\t124: \t-\t125:  개연\n","126: \t성\t127: \t어요\t128: \t별루\t129: \t포켓\t130: \t몬스터\t131:  짜\n","132: \tㅡㅡ\t133: \t;;\t134: \t쓰\t135: \t레\t136: \t사이코\t137:  마지막\n","138: \t더욱더\t139: \t질\t140: \t떨어트린\t141: \t난\t142: \t재미없\t143:  지\n","144: \tㅠㅠ\t145: \t라따뚜이\t146: \t서\t147: \t스머프\t148: \t봐서\t149:  그런가\n","150: \t포\t151: \t풍\t152: \t저그\t153: \t나가\t154: \t신다\t155:  영차영차\n","156: \t영차\t"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SHauuWlomQjb","colab_type":"code","outputId":"64fcf081-3380-4612-afb8-b1e042a998fc","executionInfo":{"status":"ok","timestamp":1579503476862,"user_tz":-540,"elapsed":631,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def numericalize(sent, vocab):\n","    temp= []\n","    for token in sent:\n","        if vocab.get(token) is None:\n","            temp.append(vocab['<unk>'])\n","        else:\n","            temp.append(vocab.get(token))\n","    return temp\n","\n","numerical_data = [(numericalize(sent, vocab), label) \\\n","                  for sent, label in sample_data]\n","print(numerical_data[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jeTa-zSWvX3s","colab_type":"code","outputId":"94b2bf83-a209-4d15-962b-eeb13caabcbf","executionInfo":{"status":"ok","timestamp":1579503478684,"user_tz":-540,"elapsed":652,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["print(\"패딩 이전의 문장 길이:\")\n","print([len(sent) for sent, _ in numerical_data])\n","max_len = max([len(sent) for (sent, _) in numerical_data])\n","\n","for sent, _ in numerical_data:\n","    if len(sent) < max_len:\n","        sent += [vocab['<pad>']] * (max_len - len(sent))\n","print(\"패딩 이후의 문장 길이: \")\n","print([len(sent) for sent, _ in numerical_data])\n","print(\"패딩 이후의 1번째 문장의 토큰들: \")\n","print(numerical_data[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["패딩 이전의 문장 길이:\n","[13, 17, 6, 17, 1, 8, 38, 2, 6, 20, 19, 18, 3, 9, 11, 6, 5, 15, 15, 8]\n","패딩 이후의 문장 길이: \n","[38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38]\n","패딩 이후의 1번째 문장의 토큰들: \n","([2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VNGC2W_swPRa","colab_type":"text"},"source":["## TorchText 활용하기\n","1. 필드 지정\n","2. 데이터셋 만들기\n","3. 단어장 생성\n","4. 데이터로더 설정\n"]},{"cell_type":"markdown","metadata":{"id":"tWG0bfklyvCW","colab_type":"text"},"source":["### 1. 필드 지정"]},{"cell_type":"code","metadata":{"id":"KPO6tl_1x2xU","colab_type":"code","outputId":"9fb3ba97-74c2-4622-b339-054825c74601","executionInfo":{"status":"error","timestamp":1579503751702,"user_tz":-540,"elapsed":617,"user":{"displayName":"­이찬혁[ 학부재학 / 언어학과 ]","photoUrl":"","userId":"14406785398096659913"}},"colab":{"base_uri":"https://localhost:8080/","height":351}},"source":["import torch\n","from torchtext.data import Field\n","\n","TEXT = Field(sequential=True,\n","             use_vocab=True,\n","             tokenize=tokenizer.morphs,\n","             lower=True,\n","             batch_first=True)\n","LABEL = Field(sequential=False,\n","             use_vocab=False,\n","             preprocessing=lambda x: int(x),\n","             batch_first=True,\n","              is_target=True)\n","ID = Field(sequential=False,\n","          use_vocab=False,\n","          is_target=False)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-6725e54387a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m TEXT = Field(sequential=True,\n\u001b[1;32m      5\u001b[0m              \u001b[0muse_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m __all__ += [name for name in dir(_C)\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             not name.endswith('Base')]\n","\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"38xQ6dDc32If","colab_type":"text"},"source":["### 2. 데이터셋 만들기"]},{"cell_type":"code","metadata":{"id":"IA3cNXLw3bYh","colab_type":"code","colab":{}},"source":["from torchtext.data import TabularDataset\n","\n","dataset = TabularDataset(path='./nsmc/ratings.txt',\n","                        format='tsv',\n","                        fields=[('id', ID), ('text', TEXT), ('label', LABEL)],\n","                        skip_header=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c5hk9ATO3-kJ","colab_type":"text"},"source":["### 3. 단어장 만들기"]},{"cell_type":"code","metadata":{"id":"5dWL36VO3p_b","colab_type":"code","outputId":"790c58f8-0cc4-4e77-fd07-3cb5de6f4bea","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["TEXT.build_vocab(dataset)\n","print('Total vocabulary: {}'.format(len(TEXT.vocab)))\n","print('Token for \"<unk>\": {}'.format(TEXT.vocab.stoi['<unk>']))\n","print('Token for \"<pad>\": {}'.format(TEXT.vocab.stoi['<pad>']))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Total vocabulary: 60825\n","Token for \"<unk>\": 0\n","Token for \"<pad>\": 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uayEB7164Bmi","colab_type":"text"},"source":["### 4. 데이터로더 설정"]},{"cell_type":"code","metadata":{"id":"D-KVCsPq3w68","colab_type":"code","outputId":"bf2a46fd-a01c-467a-f65a-35526a3e8c3f","colab":{"base_uri":"https://localhost:8080/","height":137}},"source":["from torchtext.data import Iterator\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","data_loader = Iterator(dataset=dataset,\n","                      batch_size=3,\n","                      device=device)\n","\n","for batch in data_loader:\n","    break\n","\n","print(batch.text.size(), batch.label.size())\n","print(batch.text)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([3, 17]) torch.Size([3])\n","tensor([[  66,    2,  304,  124,  176,  262,   24,    4,    5,    2,  397,   20,\n","            9,   32,   27,    6,    2],\n","        [ 342,    2,  294,   69,  374,   45,  138,   11, 1088, 1311,    1,    1,\n","            1,    1,    1,    1,    1],\n","        [  87,   73,  827,   10, 9230,   19,  183,   57,   22,    9,  339,   75,\n","           56,   25,    6,    1,    1]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YqxdAvJwDUZB","colab_type":"text"},"source":["## 코사인유사도"]},{"cell_type":"code","metadata":{"id":"_4OkK6J2DWNU","colab_type":"code","colab":{}},"source":["import torch\n","\n","x1 = torch.FloatTensor([1, 2, 3, 4])\n","x2 = torch.FloatTensor([1, 2, 3, 5])\n","x3 = torch.FloatTensor([1, 4, 2, 1])\n","\n","print(torch.cosine_similarity(x1, x2, dim=0))\n","print(torch.cosine_similarity(x1, x3, dim=0))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QimIkVjeDX5x","colab_type":"text"},"source":["### 원핫인코딩과 코사인유사도"]},{"cell_type":"code","metadata":{"id":"kLbi81JSDZnO","colab_type":"code","colab":{}},"source":["word1 = torch.FloatTensor([0, 0, 1, 0, 0, 0, 0, 0])\n","word2 = torch.FloatTensor([0, 0, 0, 0, 1, 0, 0, 0])\n","print(torch.cosine_similarity(word1, word2, dim=0))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFaHNv8RDcP7","colab_type":"text"},"source":["## PyTorch로 사용하는 분산표상방식"]},{"cell_type":"code","metadata":{"id":"A837K-xIDebT","colab_type":"code","colab":{}},"source":["tokens = \"We are going to watch Avengers End Game\".split()\n","new_sent = \"We are Avengers\".split()\n","vocab = {tkn: i for i, tkn in enumerate(tokens)}\n","\n","embedding = torch.FloatTensor([[ 1, 5, 7],\n","                               [2, 1, 8],\n","                               [2, 6, 2],\n","                               [1, 6, 9],\n","                               [4, 5, 9],\n","                               [3, 2, 1],\n","                               [0, 9, 5],\n","                               [2, 3, 9]])\n","\n","#새로운 문장 토큰들의 빈도표에 해당하는 인덱스\n","idxes = torch.LongTensor([vocab[tkn] for tkn in new_sent]) #인덱스는 항상 Long Tensor (정수형)\n","\n","import torch.nn as nn\n","embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n","                               embedding_dim=3,\n","                               _weight=embedding)\n","print(embedding_layer(idxes))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YZdraAmkDhus","colab_type":"text"},"source":["## Word2Vec을 사용한 임베딩 행렬"]},{"cell_type":"markdown","metadata":{"id":"hePftKehDlLg","colab_type":"text"},"source":["Colab에 gensim 설치하기"]},{"cell_type":"code","metadata":{"id":"UIiMUTqJDo7j","colab_type":"code","colab":{}},"source":["! pip install -U gensim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csRd3dE_Ds6v","colab_type":"code","colab":{}},"source":["from konlpy.tag import Mecab\n","from gensim.models.word2vec import Word2Vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2X3g5ksDwd3","colab_type":"code","colab":{}},"source":["mecab = Mecab()\n","tokenizer = lambda x: [\"/\".join(y) for y in mecab.pos(x)]\n","\n","f = open(\"/content/ratings.txt\")\n","raw_data = f.read().splitlines()[1: ]\n","f.close()\n","data = [line.split(\"\\t\")[1] for line in raw_data]\n","data = [tokenizer(sent) for sent in data]\n","\n","model = Word2Vec(sentences=data, size=100, window=5, min_count=3, sg=1)\n","#sentences: 문장 데이터. 하나의 list 속에 토큰화된 문장 list의 형태\n","#size: 임베딩 벡터의 크기\n","#window: skip-gram/CBoW 윈도우 크기\n","#min_count: 최소 등장 횟수\n","#sg: 1 if skip-gram; 0 if CBoW\n","\n","print(\"단어 임베딩 행렬 크기 : \", model.wv.vectors.shape)\n","#학습한 모델 저장\n","model.wv.save_word2vec_format(\"/content/word2vec.pt\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYN1MDECD0JY","colab_type":"text"},"source":["### 학습한 모델을 사용해 코사인 유사도 구하기"]},{"cell_type":"code","metadata":{"id":"HGf7ALhbD237","colab_type":"code","colab":{}},"source":["sim1 = model.wv.similarity(*tokenizer(\"배우 여배우\"))\n","sim2 = model.wv.similarity(*tokenizer(\"배우 교수\"))\n","print(\"similarity(배우, 여배우) {:.2f}\".format(sim1))\n","print(\"similarity(배우, 교수) {:.2f}\".format(sim2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-bMPtDUD6rj","colab_type":"code","colab":{}},"source":["sim3 = model.wv.most_similar(tokenizer(\"스토리\"), topn=5)\n","for t, s in sim3:\n","  print(\"{} = {:.2f}\".format(t, s))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmyIkRazD9O1","colab_type":"code","colab":{}},"source":["sim4 = model.wv.most_similar(positive=tokenizer(\"여배우\"), \n","                             negative=tokenizer(\"남자\"),\n","                             topn=1)\n","print(sim4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZR1c8nWKMWzy","colab_type":"text"},"source":["# 순환 신경망\n","\n","> 3.2.4 장에 해당하는 코드"]},{"cell_type":"code","metadata":{"id":"TJqPQrvMMYs1","colab_type":"code","colab":{}},"source":["# 코드 3-35\n","\n","import torch\n","import torch.nn as nn\n","\n","class CustomRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, batch_first=True):\n","        super(CustomRNN, self).__init__()\n","        # 선형결합에 사용할 학습가능한 매개변수를 생성한다.\n","        self.weight_xh, self.weight_hh, self.bias = \\\n","            self.init_weight(input_size, hidden_size)\n","        # 필요한 정보를 저장한다\n","        self.hidden_size = hidden_size\n","        self.batch_first = batch_first\n","        \n","    def forward(self, inputs):\n","        \"\"\"\n","        rnn_cell 을 구동하기 위해 inputs 의 크기 (T, B, E) 형태가 되어야 한다.\n","         - T: 시퀀스 총 길이\n","         - B: 미니배치크기\n","         - E: 입력층 크기 \n","        \"\"\"\n","        if self.batch_first:\n","            # 첫번째 차원이 미니배치 크기인 경우 전치연산으로 바꿔준다.\n","            inputs = inputs.transpose(0, 1)\n","        seqlen, batch_size, _ = inputs.size()\n","        # 0 time-step 에서 은닉층 값을 0으로 초기화 시킨다\n","        hidden = self.init_hidden(batch_size, self.hidden_size)\n","        # output에 은닉층의 출력값을 저장한다.\n","        output = []\n","        # 시퀀스의 총 길이만큼 순방향전파를 진행한다.\n","        for i in range(seqlen):\n","            hidden = self.rnn_cell(inputs[i], hidden)\n","            output.append(hidden)\n","        output = torch.stack(output)\n","        if self.batch_first:\n","            output = output.transpose(0, 1)\n","        # 모든 타임스텝의 은닉층 출력값과 마지막 타임 스텝의 은닉층 출력값을 각각 반환한다.\n","        return output, hidden\n","    \n","    def rnn_cell(self, x, h):\n","        \"\"\"RNN Cell\"\"\"\n","        h = x.mm(self.weight_xh.t()) + h.mm(self.weight_hh.t()) + self.bias\n","        return torch.tanh(h)\n","    \n","    def init_hidden(self, batch_size, hidden_size):\n","        \"\"\"0 타임스텝에서 은닉층의 초기화\"\"\"\n","        return torch.zeros(batch_size, hidden_size)\n","    \n","    def init_weight(self, input_size, hidden_size):\n","        \"\"\"rnn_cell 의 선형결합을 위한 초기값\"\"\"\n","        weight_xh = torch.randn(hidden_size, input_size).requires_grad_()\n","        weight_hh = torch.randn(hidden_size, hidden_size).requires_grad_()\n","        bias = torch.zeros(1, hidden_size).requires_grad_()\n","        return weight_xh, weight_hh, bias"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AIKOrWibMbc1","colab_type":"code","colab":{}},"source":["# 코드 3-36\n","\n","# RNN 호출 방법\n","\n","rnn_layer = nn.RNN(input_size=5, hidden_size=10, batch_first=True)\n","\n","# LSTM 호출 방법\n","#rnn_layer = nn.LSTM(input_size=5, hidden_size=10, batch_first=True) \n","#print(rnn_layer)\n","\n","# GRU 호출 방법\n","#rnn_layer = nn.GRU(input_size=5, hidden_size=10, batch_first=True)\n","#print(rnn_layer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAOKxrvUMdR-","colab_type":"code","colab":{}},"source":["# 코드 3-37\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","torch.manual_seed(70)\n","\n","sentence = \"We are going to watch Advengers End Game\".split()\n","vocab = {tkn: i for i, tkn in enumerate(sentence, 1)}  # 단어리스트 생성\n","vocab['<unk>'] = 0\n","# 수치화된 데이터를 단어로 바꾸기 위한 사전\n","rev_vocab = {v: k for k, v in vocab.items()}\n","# 수치화된 데이터를 단어로 전환하는 함수\n","decode = lambda y: [rev_vocab.get(x) for x in y]  \n","\n","def construct_data(sentence, vocab):\n","    \"\"\"\n","    (input, target) 쌍으로 데이터를 생성한다.\n","    - 최종 형태(수치화된 단어 쌍):\n","     [(We,are) ,(are,going), (going,to), (to,watch), \n","        (watch,Avengers), (Avengers,End), (End,Game)]\n","    \"\"\"\n","    numericalize = lambda x: vocab.get(x) if vocab.get(x) is not None else 0\n","    totensor = lambda x: torch.LongTensor(x)\n","    idxes = [numericalize(token) for token in sentence]\n","    x, t = idxes[:-1], idxes[1:]\n","    return totensor(x).unsqueeze(0), totensor(t).unsqueeze(0)\n","\n","class Net(nn.Module):\n","    \"\"\"예제 문장을 출력하는 모델\"\"\"\n","    def __init__(self, vocab_size, input_size, hidden_size, batch_first=True):\n","        super(Net, self).__init__()\n","        \"\"\"\n","        vocab_size: 단어장의 크기\n","        input_size: 임베딩 크기 = RNN의 입력층 크기\n","        hidden_size: RNN의 은닉층 크기\n","        \"\"\"\n","        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, \n","                                            embedding_dim=input_size)\n","        self.rnn_layer = nn.RNN(input_size, hidden_size,\n","                                batch_first=batch_first)\n","        self.linear = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        텐서 크기 변화 위한 문자 설명 \n","         - V: 단어장 크기\n","         - T: 시퀀스 총 길이\n","         - B: 미니배치 크기\n","         - E: 임베딩 크기 = RNN의 입력층 크기 \n","         - D: RNN 은닉층 크기\n","        \"\"\"\n","        # 1. embedding 층을 총과해서 분산 표상 방식으로 단어를 표현\n","        # 크기변화: (B, T) > (B, T, D)\n","        output = self.embedding_layer(x)\n","        # 2. RNN 층\n","        # 크기변화: (B, T, D) > output (B, T, D), hidden (1, B, D)\n","        output, hidden = self.rnn_layer(output)\n","        # 3. 최종 출력층\n","        # 크기변화: (B, T, D) > (B, T, V)\n","        output = self.linear(output)\n","        # 4. 모델 출력: \n","        # 크기변화: (B, T, V) > (B*T, V)\n","        return output.view(-1, output.size(2))\n","        \n","# -----------------------------------------\n","# 데이터 생성\n","x, t = construct_data(sentence, vocab)\n","\n","# 모델 생성을 위한 하이퍼 파라미터 설정\n","vocab_size = len(vocab)  # 단어장의 크기는 임베딩 층, 최종 출력층에 사용된다\n","input_size = 5  # 임베딩된 차원의 크기 및 RNN 층 입력 차원의 크기\n","hidden_size = 20  # RNN의 은닉층 크기\n","\n","# 모델 생성\n","model = Net(vocab_size, input_size, hidden_size, batch_first=True)\n","# 손실함수 정의\n","loss_function = nn.CrossEntropyLoss()\n","# 옵티마이저 정의\n","optimizer = optim.Adam(params=model.parameters())\n","\n","# 훈련 시작\n","for step in range(151):\n","    # 경사 초기화\n","    optimizer.zero_grad()\n","    # 순방향 전파\n","    output = model(x)\n","    # 손실값 계산\n","    loss = loss_function(output, t.view(-1))\n","    # 역방향 전파\n","    loss.backward()\n","    # 매개변수 업데이트\n","    optimizer.step()\n","    # 기록\n","    if step % 10 == 0:\n","        print(\"[{:02d}/151] {:.4f} \".format(step+1, loss))\n","        pred = output.softmax(-1).argmax(-1).tolist()\n","        print(\" \".join([\"We\"] + decode(pred)))\n","        print()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v30JRbYrMl4F","colab_type":"text"},"source":["# Deep RNN 과 Bidirectional RNN\n","\n","> 3.2.5 장에 해당하는 코드"]},{"cell_type":"markdown","metadata":{"id":"mTHHkonsMoF2","colab_type":"text"},"source":["## Stacked RNN"]},{"cell_type":"code","metadata":{"id":"I_AF_PWfMqIG","colab_type":"code","colab":{}},"source":["# 코드 3-38\n","\n","import torch\n","import torch.nn as nn\n","\n","def is_equal(x, y):\n","    \"\"\"두 텐서가 일치하는지 확인하는 함수\"\"\"\n","    return bool(x.eq(y).eq(0).sum() == 0)\n","\n","# T: 시퀀스 총 길이\n","# B: 미니배치 크기\n","# E: RNN의 입력층 크기 \n","# D: RNN 은닉층 크기\n","# K: RNN 층의 개수(은닉층 깊이)\n","\n","# 입력크기 (B, T, E) = (4, 7, 5)\n","sample_input = torch.randn(4, 7, 5)\n","\n","# 층이 3개인 Stacked RNN 정의\n","rnn_layer = nn.RNN(input_size=5, \n","                   hidden_size=4, \n","                   num_layers=3,\n","                   batch_first=True)\n","print(rnn_layer)\n","\n","output, hidden = rnn_layer(sample_input)\n","# output 크기: (B, T, D)\n","print(\"Output Size {}\".format(output.size()))\n","# hidden 크기: (K, B, D)\n","print(\"Hidden Size {}\".format(hidden.size()))\n","\n","# 마지막 타임스텝의 K층 출력값(output[:, -1, :])과 \n","# 은닉층의 마지막 층 값(hidden[-1])이 일치하는지 확인\n","print(\"output[:, -1, :] == hidden[-1]? {}\".format(\n","    is_equal(output[:, -1, :], hidden[-1])))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ykXN7rhMMs-O","colab_type":"text"},"source":["## Bidirectional RNN"]},{"cell_type":"code","metadata":{"id":"YEEH5JFfMu5j","colab_type":"code","colab":{}},"source":["# 코드 3-39\n","\n","import torch\n","import torch.nn as nn\n","\n","def is_equal(x, y):\n","    \"\"\"두 텐서가 일치하는지 확인하는 함수\"\"\"\n","    return bool(x.eq(y).eq(0).sum() == 0)\n","\n","# T: 시퀀스 총 길이\n","# B: 미니배치 크기\n","# E: RNN의 입력층 크기 \n","# D: RNN 은닉층 크기\n","# K: RNN 층의 개수(은닉층 깊이)\n","\n","# 입력크기 (B, T, E) = (4, 7, 5)\n","sample_input = torch.randn(4, 7, 5)\n","\n","# 층이 3개인 Bidirectional RNN 정의\n","rnn_layer = nn.RNN(input_size=5, \n","                   hidden_size=4, \n","                   num_layers=3,\n","                   batch_first=True,\n","                   bidirectional=True)\n","print(rnn_layer)\n","\n","output, hidden = rnn_layer(sample_input)\n","# output 크기: (B, T, 2*D)\n","print(\"Output Size {}\".format(output.size()))\n","# hidden 크기: (2*K, B, D)\n","print(\"Hidden Size {}\".format(hidden.size()))\n","\n","# 첫번째 미니배치에서, output의 마지막 타임스텝의 정방향 은닉값과 \n","# hidden의 마지막층 정방향 은닉값이 일치하는 지 확인\n","print(\"output[0, -1, :-4] == hidden[-2, 0, :]? {}\".format(\n","    is_equal(output[0, -1, :-4], hidden[-2, 0, :])))\n","\n","# 첫번째 미니배치에서, output의 첫번째 타임스텝의 역방향 은닉값과 \n","# hidden의 마지막층 역방향 은닉값이 일치하는 지 확인\n","print(\"output[0, 0, -4:] == hidden[-1, 0, :]? {}\".format(\n","    is_equal(output[0, 0, -4:], hidden[-1, 0, :])))"],"execution_count":0,"outputs":[]}]}